{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic Character Model trainer/predictor",
      "provenance": [],
      "authorship_tag": "ABX9TyNxmdVb1Bo6AgCWIEse18Xe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/styndall/nlp_tools/blob/master/Basic_Character_Model_trainer_predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci5_xGrblhOX"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLgTWEKUhpGC",
        "outputId": "a48b727b-aa73-453e-8c73-7be18035ac3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')  "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWTfl-DblqgE"
      },
      "source": [
        "# some quick stuff to clean up data\n",
        "def get_dict_from_column(df, col_name):\n",
        "  col = df[col_name]\n",
        "  col_dict = dict(zip(df[col_name].unique(), range(1, df[col_name].nunique()+1)))\n",
        "  for k in col_dict:\n",
        "    if col_dict[k] == '':\n",
        "      col_dict[k] = 0\n",
        "  return col_dict\n",
        "\n",
        "def get_all_col_dicts(df):\n",
        "  col_dicts = {}\n",
        "  for col in df:\n",
        "    col_dicts[col] = get_dict_from_column(df, col)\n",
        "  return col_dicts\n",
        "\n",
        "def replace_cols_with_numerical(df):\n",
        "  col_dicts = get_all_col_dicts(df)\n",
        "  transformed_df = pd.DataFrame()\n",
        "  for col in df.columns:\n",
        "    transformed_df[col] = df[col].map(col_dicts[col])\n",
        "\n",
        "  return transformed_df\n",
        "\n",
        "def get_original_df_from_numerical(df, col_dict):\n",
        "  reversed_col_dict = {}\n",
        "  for col in col_dict:\n",
        "    reversed_col_dict[col] = reverse(col_dict[col])\n",
        "\n",
        "def get_all_reverse_dicts(col_dicts):\n",
        "  reverse_dicts = {}\n",
        "  for col in col_dicts.keys():\n",
        "    reverse_dicts[col] = reverse_dict(col_dicts[col])\n",
        "  \n",
        "  return reverse_dicts\n",
        "\n",
        "def reverse_dict(col_dict):\n",
        "  reverse_dict = {v:k for k, v in col_dict.items()}\n",
        "  reverse_dict[0] = ''\n",
        "  return reverse_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtRuh_ddxZhx"
      },
      "source": [
        "def get_diff_col(col):\n",
        "  out = [col[0]]\n",
        "  for i in range(1, len(col)):\n",
        "    out.append(col[i] - col[i-1])\n",
        "\n",
        "  return out\n",
        "\n",
        "def reverse_get_diff_col(col, min_val):\n",
        "  if min_val != 0:\n",
        "    for i in range(len(col)):\n",
        "      col[i] = col[i] + min_val\n",
        "  out = [col[0]]\n",
        "  for i in range(1, len(col)):\n",
        "    out.append(col[i] + out[i-1])\n",
        "\n",
        "  return out\n",
        "\n",
        "def blur_time_col(time_col, seconds=2):\n",
        "  # this is a list of epoch timestamps, alter at random by a few seconds\n",
        "  final_col = [i + random.randint(0, seconds) for i in time_col]\n",
        "  \n",
        "\n",
        "  return final_col\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7VrAPSNmFOE",
        "outputId": "6e1d737a-f5e0-40bf-bd4d-47700a128e15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# XXX get training data, import as string\n",
        "with open(\"gdrive/My Drive/british_pub_names/pub_name_list.txt\") as f:\n",
        "  data = f.read()\n",
        "data[0:25]\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Anchor Bankside\\nThe Bedfo'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkFdgFNsY39R",
        "outputId": "14dfcd10-03bb-4316-fa93-e8e255484ba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "print(data[0:100])\n",
        "len(data[15:20])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Anchor Bankside\n",
            "The Bedford\n",
            "Bell Savage Inn\n",
            "The Bishop's Finger\n",
            "The Black Friar, Blackfriars\n",
            "Black L\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPcqRm_zuo8d"
      },
      "source": [
        "data_as_list = data\n",
        "unique_elements = list(set(data_as_list))\n",
        "ele2idx = {}\n",
        "idx2ele = {}\n",
        "for i in range(len(unique_elements)):\n",
        "  ele2idx[unique_elements[i]] = i\n",
        "  idx2ele[i] = unique_elements[i]\n",
        "\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1f-8jAgvEZl",
        "outputId": "92f7af2f-1388-41fd-8584-758be6df2973",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "transformed_data_as_list = [ele2idx[x] for x in data_as_list]\n",
        "transformed_data_as_list[0:25]\n",
        "print(len(transformed_data_as_list))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1Q-FkvrSDaM"
      },
      "source": [
        "# set up everything for training (I should really make a simple library\n",
        "# and just import it)\n",
        "def train(data_col, training_epochs = 10, model_name=None):\n",
        "  distinct_values = len(set(data_col)) + 1\n",
        "\n",
        "  # sequence_length is how far we look back in our list to predict the\n",
        "  # nth character, i.e. n-10..n-1 is the sequence, n is the predicted char\n",
        "  sequence_length = 7\n",
        "\n",
        "  examples_per_epoch = len(data_col)//(sequence_length+1)\n",
        "  col_dataset = tf.data.Dataset.from_tensor_slices(data_col)\n",
        "  #split into paired sequences, target with the next sequence item\n",
        "  sequences = col_dataset.batch(sequence_length+1, drop_remainder=True)\n",
        "  dataset = sequences.map(split_input_target_seq)\n",
        "\n",
        "  # set up batches\n",
        "  batch_size = 64\n",
        "  buffer_size = 10000\n",
        "\n",
        "  #shuffle, do we need to do this for non-char-type sequences?\n",
        "  dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
        "\n",
        "\n",
        "  #set up some model values\n",
        "\n",
        "  embedding_dims = 256 #pretty standard dim count\n",
        "  rnn_units = 1024\n",
        "\n",
        "\n",
        "  model = build_model(distinct_values, embedding_dims, rnn_units, batch_size)\n",
        "  model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  # set up checkpoints with sensible names\n",
        "  if model_name:\n",
        "    checkpoint_dir = \"gdrive/My Drive/tf_models/{}/checkpoints\".format(model_name)\n",
        "  else:\n",
        "    checkpoint_dir = \"gdrive/My Drive/tf_models/checkpoints\"\n",
        "  checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "  checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    monitor='accuracy',\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True)\n",
        "  \n",
        "  # TRAIN!!!\n",
        "  epochs = training_epochs\n",
        "  history = model.fit(dataset, epochs=epochs, callbacks=[checkpoint_callback])\n",
        "\n",
        "  predictor_model = build_model(distinct_values, embedding_dims, rnn_units, batch_size=1)\n",
        "  predictor_model.set_weights(model.get_weights())\n",
        "\n",
        "  return predictor_model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# set the lstm model up\n",
        "def build_model(distinct_values, embedding_dims, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(distinct_values, embedding_dims,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True),\n",
        "    tf.keras.layers.Dense(distinct_values)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "def split_input_target_seq(seq):\n",
        "  input = seq[:-1]\n",
        "  target = seq[1:]\n",
        "  return input, target\n",
        "\n",
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "\n",
        "def get_latest_model(vocab_size, embedding_dims, rnn_units):\n",
        "  model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "  model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "  model.build(tf.TensorShape([1, None]))\n",
        "  return model\n",
        "\n",
        "def generate_seq(model, start_seq, target_length=100, temperature=1.0):\n",
        "\n",
        "  # Number of elements to generate\n",
        "  num_generate = target_length\n",
        "  \n",
        "  input_eval = tf.expand_dims(start_seq, 0)\n",
        "\n",
        "  seq_generated = []\n",
        "\n",
        "  #how crazy do we want the results? low = less crazy, high = more\n",
        "\n",
        "\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "    # remove the batch dimension\n",
        "    predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "    # using a categorical distribution to predict the character returned by the model\n",
        "    predictions = predictions / temperature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "    # We pass the predicted character as the next input to the model\n",
        "    # along with the previous hidden state\n",
        "    input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    seq_generated.append(predicted_id)\n",
        "\n",
        "  return seq_generated"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9lcn5s5xGg0"
      },
      "source": [
        "# Idea for per-column training: vocab is strings, basically - combinations of the rows, turned to strings\n",
        "# for the cols with large nuniques, use a histogram or other dimensionality reducing something"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGp2mxdydclL",
        "outputId": "6d97fbcf-b94c-4c4b-e8f9-bdd2d23be686",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = train(transformed_data_as_list, training_epochs=100)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 3.8419 - accuracy: 0.0930\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 3.3638 - accuracy: 0.1301\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 3.1781 - accuracy: 0.1964\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 31ms/step - loss: 2.8213 - accuracy: 0.2586\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 2.5213 - accuracy: 0.2909\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 2.3804 - accuracy: 0.3137\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 2.2958 - accuracy: 0.3290\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 2.2198 - accuracy: 0.3475\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 1s 52ms/step - loss: 2.1586 - accuracy: 0.3688\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 2.1035 - accuracy: 0.3826\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 2.0565 - accuracy: 0.3933\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 1.9929 - accuracy: 0.4121\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 1.9424 - accuracy: 0.4187\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 1.8950 - accuracy: 0.4418\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 1.8451 - accuracy: 0.4521\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 1.7779 - accuracy: 0.4704\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 1.7226 - accuracy: 0.4891\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 1s 50ms/step - loss: 1.6753 - accuracy: 0.5006\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 1.6238 - accuracy: 0.5214\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 33ms/step - loss: 1.5749 - accuracy: 0.5324\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 1s 55ms/step - loss: 1.5281 - accuracy: 0.5540\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 1.4728 - accuracy: 0.5671\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 1s 46ms/step - loss: 1.4209 - accuracy: 0.5897\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 1s 39ms/step - loss: 1.3922 - accuracy: 0.5945\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 3s 174ms/step - loss: 1.3343 - accuracy: 0.6167\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 33ms/step - loss: 1.2919 - accuracy: 0.6260\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 3s 178ms/step - loss: 1.2445 - accuracy: 0.6429\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 1s 36ms/step - loss: 1.2214 - accuracy: 0.6537\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 3s 168ms/step - loss: 1.1886 - accuracy: 0.6637\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 1s 36ms/step - loss: 1.1437 - accuracy: 0.6743\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 1s 44ms/step - loss: 1.1326 - accuracy: 0.6810\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 2s 125ms/step - loss: 1.1147 - accuracy: 0.6876\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 1s 37ms/step - loss: 1.0915 - accuracy: 0.6936\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 3s 228ms/step - loss: 1.0539 - accuracy: 0.7018\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 1.0442 - accuracy: 0.7043\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 1s 42ms/step - loss: 1.0264 - accuracy: 0.7146\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 5s 301ms/step - loss: 1.0051 - accuracy: 0.7156\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 0.9813 - accuracy: 0.7225\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.9724 - accuracy: 0.7216\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 3s 177ms/step - loss: 0.9540 - accuracy: 0.7292\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 0.9410 - accuracy: 0.7308\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.9235 - accuracy: 0.7304\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 0.9177 - accuracy: 0.7393\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.9026 - accuracy: 0.7381\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 3s 231ms/step - loss: 0.8892 - accuracy: 0.7412\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 30ms/step - loss: 0.8983 - accuracy: 0.7446\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.8710 - accuracy: 0.7436\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 0.8676 - accuracy: 0.7451\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 2s 152ms/step - loss: 0.8659 - accuracy: 0.7454\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 1s 38ms/step - loss: 0.8495 - accuracy: 0.7555\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.8470 - accuracy: 0.7510\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.8441 - accuracy: 0.7491\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.8292 - accuracy: 0.7509\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.8407 - accuracy: 0.7507\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 3s 225ms/step - loss: 0.8203 - accuracy: 0.7560\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 32ms/step - loss: 0.8100 - accuracy: 0.7592\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.8055 - accuracy: 0.7582\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.8061 - accuracy: 0.7570\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.8074 - accuracy: 0.7571\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 1s 39ms/step - loss: 0.7891 - accuracy: 0.7646\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 1s 86ms/step - loss: 0.7748 - accuracy: 0.7665\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7922 - accuracy: 0.7560\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.7861 - accuracy: 0.7647\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 29ms/step - loss: 0.7784 - accuracy: 0.7676\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7892 - accuracy: 0.7646\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.7767 - accuracy: 0.7621\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 4s 241ms/step - loss: 0.7733 - accuracy: 0.7682\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 32ms/step - loss: 0.7686 - accuracy: 0.7690\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.7705 - accuracy: 0.7662\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.7643 - accuracy: 0.7652\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.7548 - accuracy: 0.7668\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 1s 39ms/step - loss: 0.7458 - accuracy: 0.7719\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7550 - accuracy: 0.7676\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.7569 - accuracy: 0.7661\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7529 - accuracy: 0.7699\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.7549 - accuracy: 0.7638\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7406 - accuracy: 0.7716\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7393 - accuracy: 0.7693\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7417 - accuracy: 0.7699\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7397 - accuracy: 0.7685\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 23ms/step - loss: 0.7397 - accuracy: 0.7728\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.7351 - accuracy: 0.7699\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7273 - accuracy: 0.7720\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.7226 - accuracy: 0.7708\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 2s 119ms/step - loss: 0.7220 - accuracy: 0.7731\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.7191 - accuracy: 0.7711\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 28ms/step - loss: 0.7202 - accuracy: 0.7735\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 1s 34ms/step - loss: 0.7241 - accuracy: 0.7762\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7234 - accuracy: 0.7701\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.7126 - accuracy: 0.7714\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.7224 - accuracy: 0.7720\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7213 - accuracy: 0.7729\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7124 - accuracy: 0.7744\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.7094 - accuracy: 0.7725\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7295 - accuracy: 0.7704\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.7062 - accuracy: 0.7738\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 27ms/step - loss: 0.6900 - accuracy: 0.7826\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.7100 - accuracy: 0.7749\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7110 - accuracy: 0.7737\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.7088 - accuracy: 0.7747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSda3VS63-bY",
        "outputId": "bbfbe846-df78-4d12-f31d-900bf2c73b5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.save(\"gdrive/My Drive/british_pub_names/model/1\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: gdrive/My Drive/british_pub_names/model/1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46dOauyVg5be"
      },
      "source": [
        "def predict_from_data(data_column, training_epochs=100, number_of_predictions=6000):\n",
        "  #train the model\n",
        "  print(\"Starting training\")\n",
        "  model = train(data_column, training_epochs=training_epochs)\n",
        "  print(\"Finished training, predicting\")\n",
        "  predictions = generate_seq(model, data_column[0:60], target_length=number_of_predictions)\n",
        "  print(\"Finished predicting\")\n",
        "  return predictions\n",
        "\n",
        "def data_from_transformed(data_list, transform_dict):\n",
        "  final_data = []\n",
        "  for i in data_list:\n",
        "    final_data.append(transform_dict.get(i, 0))\n",
        "  return final_data"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUkta7Soh9YL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2whN07YnfUJ"
      },
      "source": [
        "def train_and_gen_csv(input_data, reverse_dict, training_epochs=10):\n",
        "  generated_frame = pd.DataFrame()\n",
        "\n",
        "  print(\"Training and predicting\")\n",
        "  prediction = predict_from_data(input_data, training_epochs=training_epochs)\n",
        "\n",
        "  print(\"Reconstructing data\")\n",
        "\n",
        "  final = [reverse_dict[i] for i in prediction]\n",
        "\n",
        "\n",
        "  return final\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWC9wFpOr2tK"
      },
      "source": [
        "# preprocessing - for cols with .nunique > 10, instead, transform to difference from prior value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA-U07MzrZfU",
        "outputId": "cf451b9c-df3c-43d9-ca03-b87a4439538e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# generate new data_list\n",
        "generated_data_as_list = train_and_gen_csv(transformed_data_as_list, idx2ele, training_epochs=150)\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training and predicting\n",
            "Starting training\n",
            "Epoch 1/150\n",
            "14/14 [==============================] - 0s 28ms/step - loss: 3.9897 - accuracy: 0.0770\n",
            "Epoch 2/150\n",
            "14/14 [==============================] - 0s 31ms/step - loss: 3.4144 - accuracy: 0.1137\n",
            "Epoch 3/150\n",
            "14/14 [==============================] - 0s 28ms/step - loss: 3.2636 - accuracy: 0.1513\n",
            "Epoch 4/150\n",
            "14/14 [==============================] - 0s 29ms/step - loss: 3.0175 - accuracy: 0.2226\n",
            "Epoch 5/150\n",
            "14/14 [==============================] - 0s 30ms/step - loss: 2.6777 - accuracy: 0.2797\n",
            "Epoch 6/150\n",
            "14/14 [==============================] - 0s 31ms/step - loss: 2.4592 - accuracy: 0.3037\n",
            "Epoch 7/150\n",
            "14/14 [==============================] - 0s 30ms/step - loss: 2.3411 - accuracy: 0.3170\n",
            "Epoch 8/150\n",
            "14/14 [==============================] - 1s 55ms/step - loss: 2.2721 - accuracy: 0.3371\n",
            "Epoch 9/150\n",
            "14/14 [==============================] - 0s 25ms/step - loss: 2.1956 - accuracy: 0.3611\n",
            "Epoch 10/150\n",
            "14/14 [==============================] - 0s 30ms/step - loss: 2.1394 - accuracy: 0.3731\n",
            "Epoch 11/150\n",
            "14/14 [==============================] - 0s 32ms/step - loss: 2.1126 - accuracy: 0.3772\n",
            "Epoch 12/150\n",
            "14/14 [==============================] - 0s 29ms/step - loss: 2.0451 - accuracy: 0.3938\n",
            "Epoch 13/150\n",
            "14/14 [==============================] - 0s 31ms/step - loss: 1.9890 - accuracy: 0.4136\n",
            "Epoch 14/150\n",
            "14/14 [==============================] - 0s 28ms/step - loss: 1.9604 - accuracy: 0.4208\n",
            "Epoch 15/150\n",
            "14/14 [==============================] - 0s 28ms/step - loss: 1.9005 - accuracy: 0.4310\n",
            "Epoch 16/150\n",
            "14/14 [==============================] - 1s 61ms/step - loss: 1.8594 - accuracy: 0.4515\n",
            "Epoch 17/150\n",
            "14/14 [==============================] - 0s 25ms/step - loss: 1.8087 - accuracy: 0.4576\n",
            "Epoch 18/150\n",
            "14/14 [==============================] - 0s 28ms/step - loss: 1.7574 - accuracy: 0.4713\n",
            "Epoch 19/150\n",
            "14/14 [==============================] - 0s 29ms/step - loss: 1.7196 - accuracy: 0.4837\n",
            "Epoch 20/150\n",
            "14/14 [==============================] - 0s 28ms/step - loss: 1.6763 - accuracy: 0.5033\n",
            "Epoch 21/150\n",
            "14/14 [==============================] - 0s 31ms/step - loss: 1.6241 - accuracy: 0.5080\n",
            "Epoch 22/150\n",
            "14/14 [==============================] - 0s 28ms/step - loss: 1.5643 - accuracy: 0.5368\n",
            "Epoch 23/150\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 1.5390 - accuracy: 0.5407\n",
            "Epoch 24/150\n",
            "14/14 [==============================] - 1s 59ms/step - loss: 1.4961 - accuracy: 0.5609\n",
            "Epoch 25/150\n",
            "14/14 [==============================] - 1s 45ms/step - loss: 1.4293 - accuracy: 0.5821\n",
            "Epoch 26/150\n",
            "14/14 [==============================] - 4s 276ms/step - loss: 1.4142 - accuracy: 0.5875\n",
            "Epoch 27/150\n",
            "14/14 [==============================] - 0s 34ms/step - loss: 1.3721 - accuracy: 0.5995\n",
            "Epoch 28/150\n",
            "14/14 [==============================] - 3s 192ms/step - loss: 1.3229 - accuracy: 0.6175\n",
            "Epoch 29/150\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 1.3090 - accuracy: 0.6304\n",
            "Epoch 30/150\n",
            "14/14 [==============================] - 1s 45ms/step - loss: 1.2659 - accuracy: 0.6384\n",
            "Epoch 31/150\n",
            "14/14 [==============================] - 3s 247ms/step - loss: 1.2271 - accuracy: 0.6475\n",
            "Epoch 32/150\n",
            "14/14 [==============================] - 1s 37ms/step - loss: 1.1871 - accuracy: 0.6610\n",
            "Epoch 33/150\n",
            "14/14 [==============================] - 3s 188ms/step - loss: 1.1796 - accuracy: 0.6641\n",
            "Epoch 34/150\n",
            "14/14 [==============================] - 0s 35ms/step - loss: 1.1557 - accuracy: 0.6732\n",
            "Epoch 35/150\n",
            "14/14 [==============================] - 3s 188ms/step - loss: 1.1158 - accuracy: 0.6834\n",
            "Epoch 36/150\n",
            "14/14 [==============================] - 0s 28ms/step - loss: 1.0804 - accuracy: 0.6983\n",
            "Epoch 37/150\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.0721 - accuracy: 0.6952\n",
            "Epoch 38/150\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 1.0568 - accuracy: 0.7014\n",
            "Epoch 39/150\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.0348 - accuracy: 0.7014\n",
            "Epoch 40/150\n",
            "14/14 [==============================] - 3s 248ms/step - loss: 1.0251 - accuracy: 0.7133\n",
            "Epoch 41/150\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.0059 - accuracy: 0.7113\n",
            "Epoch 42/150\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.9963 - accuracy: 0.7160\n",
            "Epoch 43/150\n",
            "14/14 [==============================] - 3s 189ms/step - loss: 0.9815 - accuracy: 0.7205\n",
            "Epoch 44/150\n",
            "14/14 [==============================] - 0s 31ms/step - loss: 0.9695 - accuracy: 0.7266\n",
            "Epoch 45/150\n",
            "14/14 [==============================] - 0s 31ms/step - loss: 0.9412 - accuracy: 0.7321\n",
            "Epoch 46/150\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.9289 - accuracy: 0.7310\n",
            "Epoch 47/150\n",
            "14/14 [==============================] - 4s 262ms/step - loss: 0.9222 - accuracy: 0.7331\n",
            "Epoch 48/150\n",
            "14/14 [==============================] - 0s 27ms/step - loss: 0.9251 - accuracy: 0.7385\n",
            "Epoch 49/150\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.9050 - accuracy: 0.7376\n",
            "Epoch 50/150\n",
            "14/14 [==============================] - 3s 191ms/step - loss: 0.9037 - accuracy: 0.7404\n",
            "Epoch 51/150\n",
            "14/14 [==============================] - 0s 29ms/step - loss: 0.8935 - accuracy: 0.7435\n",
            "Epoch 52/150\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.8938 - accuracy: 0.7377\n",
            "Epoch 53/150\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 0.8817 - accuracy: 0.7446\n",
            "Epoch 54/150\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.8752 - accuracy: 0.7431\n",
            "Epoch 55/150\n",
            "14/14 [==============================] - 2s 142ms/step - loss: 0.8643 - accuracy: 0.7468\n",
            "Epoch 56/150\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 0.8328 - accuracy: 0.7519\n",
            "Epoch 57/150\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.8444 - accuracy: 0.7519\n",
            "Epoch 58/150\n",
            "14/14 [==============================] - 4s 271ms/step - loss: 0.8380 - accuracy: 0.7529\n",
            "Epoch 59/150\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.8396 - accuracy: 0.7521\n",
            "Epoch 60/150\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.8363 - accuracy: 0.7521\n",
            "Epoch 61/150\n",
            "14/14 [==============================] - 0s 31ms/step - loss: 0.8231 - accuracy: 0.7572\n",
            "Epoch 62/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.8155 - accuracy: 0.7564\n",
            "Epoch 63/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.8280 - accuracy: 0.7567\n",
            "Epoch 64/150\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.8173 - accuracy: 0.7526\n",
            "Epoch 65/150\n",
            "14/14 [==============================] - 2s 124ms/step - loss: 0.8062 - accuracy: 0.7583\n",
            "Epoch 66/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.8118 - accuracy: 0.7577\n",
            "Epoch 67/150\n",
            "14/14 [==============================] - 0s 30ms/step - loss: 0.8031 - accuracy: 0.7592\n",
            "Epoch 68/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.8075 - accuracy: 0.7585\n",
            "Epoch 69/150\n",
            "14/14 [==============================] - 0s 32ms/step - loss: 0.7882 - accuracy: 0.7636\n",
            "Epoch 70/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7920 - accuracy: 0.7616\n",
            "Epoch 71/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7849 - accuracy: 0.7605\n",
            "Epoch 72/150\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.7857 - accuracy: 0.7636\n",
            "Epoch 73/150\n",
            "14/14 [==============================] - 1s 97ms/step - loss: 0.7819 - accuracy: 0.7643\n",
            "Epoch 74/150\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.7675 - accuracy: 0.7616\n",
            "Epoch 75/150\n",
            "14/14 [==============================] - 0s 29ms/step - loss: 0.7688 - accuracy: 0.7679\n",
            "Epoch 76/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7775 - accuracy: 0.7610\n",
            "Epoch 77/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7733 - accuracy: 0.7650\n",
            "Epoch 78/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7520 - accuracy: 0.7672\n",
            "Epoch 79/150\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.7514 - accuracy: 0.7661\n",
            "Epoch 80/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7502 - accuracy: 0.7666\n",
            "Epoch 81/150\n",
            "14/14 [==============================] - 0s 33ms/step - loss: 0.7443 - accuracy: 0.7717\n",
            "Epoch 82/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7575 - accuracy: 0.7714\n",
            "Epoch 83/150\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.7497 - accuracy: 0.7707\n",
            "Epoch 84/150\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.7515 - accuracy: 0.7699\n",
            "Epoch 85/150\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.7472 - accuracy: 0.7663\n",
            "Epoch 86/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7534 - accuracy: 0.7653\n",
            "Epoch 87/150\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.7463 - accuracy: 0.7674\n",
            "Epoch 88/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7490 - accuracy: 0.7634\n",
            "Epoch 89/150\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.7463 - accuracy: 0.7706\n",
            "Epoch 90/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7353 - accuracy: 0.7701\n",
            "Epoch 91/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7434 - accuracy: 0.7656\n",
            "Epoch 92/150\n",
            "14/14 [==============================] - 1s 97ms/step - loss: 0.7263 - accuracy: 0.7752\n",
            "Epoch 93/150\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.7249 - accuracy: 0.7706\n",
            "Epoch 94/150\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.7186 - accuracy: 0.7710\n",
            "Epoch 95/150\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.7253 - accuracy: 0.7666\n",
            "Epoch 96/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7306 - accuracy: 0.7731\n",
            "Epoch 97/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7220 - accuracy: 0.7710\n",
            "Epoch 98/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7320 - accuracy: 0.7696\n",
            "Epoch 99/150\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.7307 - accuracy: 0.7647\n",
            "Epoch 100/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7125 - accuracy: 0.7731\n",
            "Epoch 101/150\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.7297 - accuracy: 0.7717\n",
            "Epoch 102/150\n",
            "14/14 [==============================] - 1s 38ms/step - loss: 0.7051 - accuracy: 0.7766\n",
            "Epoch 103/150\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.7309 - accuracy: 0.7741\n",
            "Epoch 104/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7179 - accuracy: 0.7687\n",
            "Epoch 105/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7180 - accuracy: 0.7688\n",
            "Epoch 106/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7193 - accuracy: 0.7741\n",
            "Epoch 107/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7176 - accuracy: 0.7731\n",
            "Epoch 108/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7170 - accuracy: 0.7701\n",
            "Epoch 109/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7225 - accuracy: 0.7725\n",
            "Epoch 110/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7198 - accuracy: 0.7720\n",
            "Epoch 111/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7167 - accuracy: 0.7709\n",
            "Epoch 112/150\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 0.6979 - accuracy: 0.7793\n",
            "Epoch 113/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.6998 - accuracy: 0.7728\n",
            "Epoch 114/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7056 - accuracy: 0.7714\n",
            "Epoch 115/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7194 - accuracy: 0.7693\n",
            "Epoch 116/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7058 - accuracy: 0.7747\n",
            "Epoch 117/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7052 - accuracy: 0.7733\n",
            "Epoch 118/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.6961 - accuracy: 0.7733\n",
            "Epoch 119/150\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.7091 - accuracy: 0.7752\n",
            "Epoch 120/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7101 - accuracy: 0.7710\n",
            "Epoch 121/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.6987 - accuracy: 0.7738\n",
            "Epoch 122/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.6967 - accuracy: 0.7709\n",
            "Epoch 123/150\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.7031 - accuracy: 0.7704\n",
            "Epoch 124/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7085 - accuracy: 0.7699\n",
            "Epoch 125/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.6985 - accuracy: 0.7720\n",
            "Epoch 126/150\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.6927 - accuracy: 0.7750\n",
            "Epoch 127/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.6835 - accuracy: 0.7739\n",
            "Epoch 128/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.6977 - accuracy: 0.7749\n",
            "Epoch 129/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7035 - accuracy: 0.7760\n",
            "Epoch 130/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.7757\n",
            "Epoch 131/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.6956 - accuracy: 0.7728\n",
            "Epoch 132/150\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.6872 - accuracy: 0.7755\n",
            "Epoch 133/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.6978 - accuracy: 0.7699\n",
            "Epoch 134/150\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.6950 - accuracy: 0.7750\n",
            "Epoch 135/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.6872 - accuracy: 0.7717\n",
            "Epoch 136/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.7060 - accuracy: 0.7720\n",
            "Epoch 137/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.6836 - accuracy: 0.7744\n",
            "Epoch 138/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.6862 - accuracy: 0.7766\n",
            "Epoch 139/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.6852 - accuracy: 0.7747\n",
            "Epoch 140/150\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.6866 - accuracy: 0.7741\n",
            "Epoch 141/150\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.6810 - accuracy: 0.7761\n",
            "Epoch 142/150\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.6854 - accuracy: 0.7765\n",
            "Epoch 143/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.6909 - accuracy: 0.7712\n",
            "Epoch 144/150\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.7064 - accuracy: 0.7685\n",
            "Epoch 145/150\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.6912 - accuracy: 0.7752\n",
            "Epoch 146/150\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.6718 - accuracy: 0.7779\n",
            "Epoch 147/150\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.6777 - accuracy: 0.7752\n",
            "Epoch 148/150\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.6838 - accuracy: 0.7710\n",
            "Epoch 149/150\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.6963 - accuracy: 0.7769\n",
            "Epoch 150/150\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.7754\n",
            "Finished training, predicting\n",
            "Finished predicting\n",
            "Reconstructing data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDKurvwSxHtn",
        "outputId": "21440d4a-1791-4d4a-cd63-e8a187fd5dcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(\"\".join(generated_data_as_list))\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ger\n",
            "The Toote\n",
            "Casedon\n",
            "The Dovent Garden\n",
            "Devons\n",
            "Leatshire\n",
            "Lord Shears\n",
            "Black Horses, Ismith\n",
            "The and Navern\n",
            "Fitzrovia\t\t\t\t\n",
            "Scots House, Southwark, Fitzrovia\t\t\t\t\n",
            "Crown, Coventer\t\t\t\t\n",
            "The flask\t\t\t\t\n",
            "The Flen\n",
            "Ye Old Belgs Arms, Novendon Apppttyle, Ke Arms\n",
            "Quree and Dred, Maida Vale\n",
            "Whe Crown, Islington\n",
            "The Dray Tavern\n",
            "George and Dragon, Fitzrovia\n",
            "Swan & Kenning Scotuthwark\n",
            "White Swan, Hight Bell\n",
            "Leatherd Navern, Fitzrovia\t\t\t\n",
            "The Boot, Chelsea\n",
            "The Goate\n",
            "Britre Hog\n",
            "The Bishop's Fishall\n",
            "The Hleworth\n",
            "The Colornsey\n",
            "Queen's Her\n",
            "Colehite Lion, House, Southwark\n",
            "Fox Inn, Richmond\n",
            "Denmarken ury\n",
            "The Roeh, Brixter\n",
            "The Olde Mitzrovia\n",
            "Sgar Botthese\n",
            "Two Covern Castle, Hammersmith\n",
            "Salutty Sarden\n",
            "The Duke olden\n",
            "Barlton Cour\n",
            "Ters, Covent Garden\n",
            "Ye Old Bells, Fulham\n",
            "The Wat\n",
            "Dirth\n",
            "Mawson Arms\n",
            "Arms\n",
            "Spandra, Dick\n",
            "Eavern\n",
            "The Old Bulllet\n",
            "King Edwingtorse\n",
            "The Harp\n",
            "Bricklarnes\n",
            "Wheewn and Anchor Bernchor, Harnes\n",
            "Whe Wheatsheaf, Fitzrovia\t\t\t\n",
            "The Harp\n",
            "Lather\n",
            "Rayne\n",
            "The Niardy Hanwell Arms\n",
            "Camlico\n",
            "The Bishop's Fish Thabert\n",
            "Ang's Head, Covene\n",
            "Princess Lion, Hameen's Head, Mayfair\n",
            "The Booria, Balham\n",
            "The Forest Garden\n",
            "Ye Old Queen's Hem\n",
            "The Alf Spithuck\n",
            "The George, Maida Vale\n",
            "Wheese\n",
            "Ye Old Queen\n",
            "The Barnes\n",
            "White Swan\t\t\t\t\n",
            "The Billet, Batter, Ealfiel, Folden Head\t\t\t\t\n",
            "The Dovent Garden\n",
            "Devons\n",
            "Spread and Evern\n",
            "Army\t\t\t\t\n",
            "Citting Hipan, Twich\n",
            "Harbour\n",
            "The Drayton, Hammersmith\n",
            "Duke of Yoross Keys, Putne Derown and Anchor\n",
            "The Whitzrovia\t\t\t\t\n",
            "The Old Bulham\n",
            "The Fleworth\n",
            "The George and Victck Friar, Hayes\n",
            "Blask, Hiotore Hog\n",
            "Three Hilla, Uxbridge\n",
            "Three Hog\n",
            "The Fiards Inn, Ruch Bowl, London Appple, Kensink\n",
            "Eag, Chelsea\n",
            "The Alchemislip\n",
            "The Fl Washington, Hammers, Covene\n",
            "Prince Alfueshire Arms\n",
            "Druse\n",
            "Ye Olde Cown, Islington\n",
            "The Callay Duke of Asea Pottle\n",
            "The Blackfred, Mairmentish Town Inn\n",
            "PSoho\n",
            "Sun Ca\n",
            "The Bishop's Fisheaf, Fitzrovia\n",
            "She, Hillington\n",
            "The Dragon, Fitzrovia\n",
            "Swan Inn\n",
            "PStrand-oho\n",
            "The Billet, Batte and Crown, Covent Garden\n",
            "Barlton upon House, Hilling Sun, Fitzrovia\n",
            "Sir Joh\n",
            "The King Edwn\t\t\t\t\n",
            "Princess Arms, Covent Garden\n",
            "The Duke of Yor Park\n",
            "Half Mayfair\n",
            "The Boon, Cight Bell Arms\n",
            "Carlton of Wen Bells\n",
            "The Lion, Shipwrights Arms, Belel Green\n",
            "George and Anchmond\n",
            "Denmark Washingth\n",
            "Talls\n",
            "The Gurd\n",
            "Spottmerd\n",
            "Spottm\n",
            "The White Swan Inn, Batter, Hight Bel, Mayfair\n",
            "The Harp\n",
            "Lam\n",
            "Qe Wingel, Mayfair\n",
            "The Tottenham\n",
            "Arms, Nog and Dragon, Fishol\n",
            "Hand alfields\n",
            "The Punck Tavern\n",
            "The Bedfightse\n",
            "Lord Earlsfite Crose ad\t\t\n",
            "Bull\n",
            "Leathern Rase\t\t\t\t\n",
            "Duke of Cush, Swich\n",
            "Hareen's Heameenn\n",
            "Asse, Holby\n",
            "Thepst, Kensid, Fulham\n",
            "The Fle Mitre\n",
            "Boar's Fohe Pride of Yorkshire Cheese\n",
            "Ye Old Bulewurt\n",
            "The Alouse, Southwark\n",
            "Wack Horseshoes, Chels Head, Fish Tabard\n",
            "The Bobby\n",
            "The Blavern\n",
            "Fox and Dross Kes, Payt\t\t\t\t\n",
            "The Old Quen Bells, Fulham\n",
            "The Fon Arms\n",
            "Old Shades\n",
            "White Lion, King Edington\n",
            "The Duke of Yorn\t\t\t\t\n",
            "Seven Barnes\n",
            "Wheese\n",
            "Ye Old Bull\n",
            "The Blackfrden\n",
            "The Punchite Swanchiree Horse\n",
            "Roseen Bells\n",
            "The Lion, Hoxbridge\n",
            "The Blackfred, Maight Belse\n",
            "Lord Fillet, Chelsead\t\t\t\t\n",
            "The Island Queen's Head, Pinndsleter\n",
            "The Harnes\n",
            "Wheese\n",
            "Ye Old Bull and Bishop's Fitzrovia\t\t\t\t\n",
            "Mure\n",
            "Half Maida Vale\n",
            "Wheaf, Fulham\n",
            "The White Swan-the-Greenwich\n",
            "Spand Vulth\n",
            "The Widow's Sonth\n",
            "Saluthall\n",
            "The Widow's Son, London, Belsheaf, Southwark\n",
            "Washington\n",
            "The Coand Vale\n",
            "Warwichmond\n",
            "Sueen\n",
            "Coach and House, Hop Billet, Kensing Eagle, Fulham\n",
            "The Drary\n",
            "The Blackfred, Maida Vale\n",
            "White Swan, Hampstead\t\t\t\t\n",
            "The Par\n",
            "Arms\n",
            "Flying Sun, Fitzrovia\n",
            "Sir Joho\n",
            "Puhe Palm Footman\n",
            "Nell Gwynne Tad\t\t\t\t\n",
            "The\n",
            "Crooked, Chiswuch Horseston\n",
            "Ye Old Red Lion, Ho, Fince Alfields\n",
            "Trafarylebone\n",
            "Coach and Bhe Prideaf, Fulham\n",
            "The George and Phent Garden\n",
            "ThBull and Housh\t\t\t\t\n",
            "The Dray, Stoke Newington\n",
            "The Goathern Rayn, Putney\n",
            "The Crown, Coldhickbury\t\t\t\t\t\n",
            "Crown, Islington\n",
            "The Head\n",
            "Pens Head, Hoxbridge\n",
            "Rutland Devond Anchor\n",
            "The Goate\n",
            "The Blackfred, Maida Vale\n",
            "Whee\n",
            "The White Crose, Hammersmith\n",
            "The Warrow\n",
            "Quth Tavern\n",
            "George andArms\n",
            "Arad, Pinn\n",
            "The Ters Lane Half Maida Vale\n",
            "Whington, Hampstead\t\t\t\t\n",
            "The Colde Cock, Fulham\n",
            "Dise, Hind\n",
            "The Sarden\n",
            "The Harp\n",
            "Lam\n",
            "Viaduct Grapes, Aldgon Hopmberland\n",
            "The Bish, Wellse, Ken\n",
            "Fox and Driards Head, Uxbridge\n",
            "Bull's Hee Grenarbour\n",
            "The Harp\n",
            "Lamb, Bullham\n",
            "The Fown and Arms\n",
            "Hark, Bedford\n",
            "Belloomsbury\t\t\t\t\n",
            "The Dray\n",
            "The Mida Valead, Covenchor, Hammersmith\n",
            "Salutty Sar Eag and Che Crown, Covent Garden\n",
            "Rusland Queen\n",
            "Coach and Lion, Kent, Kings Clanricarsdale\t\t\t\t\n",
            "The George of Spitall\n",
            "The Toate\n",
            "The Bearbour\n",
            "The She, Hillight Belde Cheese\n",
            "Ye Old Bells, Fulham\n",
            "The Finger\t\t\t\t\n",
            "Cross Keyswater\n",
            "The Shipwrl George, Maida Vale\n",
            "Whall Caste Horses, Islinge\n",
            "Bull's Head, Hoxby, Batteneworse\n",
            "Rose and Drk, Fitzrovia\t\t\t\t\n",
            "The Old Bel\n",
            "Denmark, Fitzroviand Delgravia\n",
            "Pross Keys, Hige Inn, Shears\n",
            "The Punch Bowl, Coventichmond\n",
            "Sun, Fitzrovia\t\t\t\t\n",
            "Seven Blackfrt, Crown, Olde Horseshoeen's Head, Fulhairmen\n",
            "The Herne Tavern\n",
            "The Alewm\n",
            "Laurie and Bive, Mar\n",
            "The Phe Tipperne, Eastcks Arms, House, Holborn\t\t\t\t\n",
            "Serne, Eason\n",
            "The Flying Toote\n",
            "Crown, Isl Tavern, Mayfair\n",
            "The Blackfred, Maida Vale\n",
            "Warsea\n",
            "The Kentonsbury\t\t\t\t\n",
            "The Roeho\n",
            "Pillan Head\n",
            "Pforde Cherr, Handy Barnes\n",
            "Dirty Sard Steern\n",
            "Charrow\n",
            "Quke's Head, Chipping Bush\n",
            "Ye Old Bush Bottle, Kensire, Balham\n",
            "The Flern\n",
            "Charon\n",
            "Boley\n",
            "Falcotsman, Kings Cros\n",
            "Jamaica CiInne, Hillinton, Crown, Covent Garden\n",
            "Ye Tavern, Blackfrtune of Grapes, Putne Hill\n",
            "The Widow's Son, Coure\n",
            "Half Ma Cady\t\t\t\t\n",
            "The Grenadbroke Hin-oho\n",
            "The Blington, Mar, Paxtons\n",
            "Handy Barn Arms, Houth Kenton, Hampstead\t\t\t\t\n",
            "The Only Room\n",
            "Rising Head\n",
            "Pleworth\n",
            "The White Swingt Garden\n",
            "Ye Old Man, Pite Beariars\n",
            "Eastcote\n",
            "Crost Garden\n",
            "Crackton, Mar\n",
            "Coal Hill\n",
            "George ard Steese\n",
            "Ye Old Bull Hanwells, Fulham\n",
            "The Blackfred, Maida Vale\n",
            "Wh Man, Putney\n",
            "The Crown, Cozrovia\n",
            "Drayton, Belse\n",
            "Lord Pussycotsman, Kingshipchmon, Plize Park\n",
            "Half Mar Oadbly House, Southwark Washington\n",
            "Royal Oak\n",
            "Half Mayfairlask, Hindermern's\n",
            "Ease, House, Southwark\n",
            "Westmeed Lion, Chelsea\n",
            "The Kiling\n",
            "Kington\n",
            "The Drayese\n",
            "Ye Old Bulliadbroke Old Beld\n",
            "Monttenhad\t\t\t\t\n",
            "The Boarbour\n",
            "The Old Bre\t\t\t\t\n",
            "The Blackfred, Maiaruthall\n",
            "The Sand\n",
            "The Blackfred, Maive, Mare Hog\n",
            "The Bishop's Fisheaf, Fitzrovia\n",
            "Sir JoInn\n",
            "The Sald Pussyck \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YelWD7jLATUZ"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpwnRBe9U3LX"
      },
      "source": [
        "generated_data = pd.DataFrame(rows, columns=[\"event_type\", \"user_id\", \"user_name\", \"company_id\", \"company_name\", \"call_id\"])\n",
        "time_col = blur_time_col(time_col[0:len(generated_data)])\n",
        "generated_data['timestamp'] = time_col"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TOSWby4eP5S",
        "outputId": "0c2c91eb-806b-4b66-ab6c-d983579fef02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "generated_data[0:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>event_type</th>\n",
              "      <th>user_id</th>\n",
              "      <th>user_name</th>\n",
              "      <th>company_id</th>\n",
              "      <th>company_name</th>\n",
              "      <th>call_id</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CallLeftEvent</td>\n",
              "      <td>e3a89054-732a-4c86-98d3-bcfe7918b092</td>\n",
              "      <td>John Gamble</td>\n",
              "      <td>570afd99-616b-4649-b899-50dcb1d8af77</td>\n",
              "      <td>Smith, Patton and Robinson</td>\n",
              "      <td>0001987e-bf61-4d40-a979-ca97c3c6fe0b</td>\n",
              "      <td>1459488133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CallLeftEvent</td>\n",
              "      <td>4ceed7a9-30a1-40c5-9cc8-afcd5db5fae6</td>\n",
              "      <td>Natalie Barron</td>\n",
              "      <td>570afd99-616b-4649-b899-50dcb1d8af77</td>\n",
              "      <td>Smith, Patton and Robinson</td>\n",
              "      <td>0001987e-bf61-4d40-a979-ca97c3c6fe0b</td>\n",
              "      <td>1459488133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CallCreatedEvent</td>\n",
              "      <td>c9c1c9e8-3788-4e60-a87e-9f8752d9b730</td>\n",
              "      <td>Jack Flores</td>\n",
              "      <td>7c015f5c-93cd-4f06-b9c6-c6dfdbfd3c1e</td>\n",
              "      <td>Leblanc PLC</td>\n",
              "      <td>b31d9a92-0867-4b78-ad5b-aed2e9fe2525</td>\n",
              "      <td>1459512944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CallLeftEvent</td>\n",
              "      <td>c9c1c9e8-3788-4e60-a87e-9f8752d9b730</td>\n",
              "      <td>Jack Flores</td>\n",
              "      <td>7c015f5c-93cd-4f06-b9c6-c6dfdbfd3c1e</td>\n",
              "      <td>Leblanc PLC</td>\n",
              "      <td>b31d9a92-0867-4b78-ad5b-aed2e9fe2525</td>\n",
              "      <td>1459512942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CallCreatedEvent</td>\n",
              "      <td>9acaa899-e559-4600-b376-af6b211833bf</td>\n",
              "      <td>James Reynolds</td>\n",
              "      <td>570afd99-616b-4649-b899-50dcb1d8af77</td>\n",
              "      <td>Smith, Patton and Robinson</td>\n",
              "      <td>b321f1c8-43b6-4284-9f50-2c5e4c70a0d5</td>\n",
              "      <td>1459513453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CallLeftEvent</td>\n",
              "      <td>9acaa899-e559-4600-b376-af6b211833bf</td>\n",
              "      <td>James Reynolds</td>\n",
              "      <td>570afd99-616b-4649-b899-50dcb1d8af77</td>\n",
              "      <td>Smith, Patton and Robinson</td>\n",
              "      <td>b321f1c8-43b6-4284-9f50-2c5e4c70a0d5</td>\n",
              "      <td>1459513453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CallCreatedEvent</td>\n",
              "      <td>6eed472b-87a7-4203-9bf2-fb0a75383a64</td>\n",
              "      <td>Latoya Schneider</td>\n",
              "      <td>a7306837-37e0-4f62-b1a4-5e257a0203e5</td>\n",
              "      <td>Brown, Duncan and Jones</td>\n",
              "      <td>b324b5d1-62d2-415f-83cf-cabf05e9f495</td>\n",
              "      <td>1459514077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>CallLeftEvent</td>\n",
              "      <td>6eed472b-87a7-4203-9bf2-fb0a75383a64</td>\n",
              "      <td>Latoya Schneider</td>\n",
              "      <td>a7306837-37e0-4f62-b1a4-5e257a0203e5</td>\n",
              "      <td>Brown, Duncan and Jones</td>\n",
              "      <td>b324b5d1-62d2-415f-83cf-cabf05e9f495</td>\n",
              "      <td>1459514074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>CallCreatedEvent</td>\n",
              "      <td>2e21e535-8ecb-45b3-a92a-a3476e08b5d6</td>\n",
              "      <td>James Mckenzie</td>\n",
              "      <td>d467376c-70b5-4a16-8936-6cd73d50d70c</td>\n",
              "      <td>Gilbert Group</td>\n",
              "      <td>b328c9a0-d813-4f09-9a2c-3dc3a922c873</td>\n",
              "      <td>1459514395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>CallJoinedEvent</td>\n",
              "      <td>50db4ef5-e202-409b-a28a-6876d9469b4b</td>\n",
              "      <td>Hannah Freeman</td>\n",
              "      <td>d467376c-70b5-4a16-8936-6cd73d50d70c</td>\n",
              "      <td>Gilbert Group</td>\n",
              "      <td>b328c9a0-d813-4f09-9a2c-3dc3a922c873</td>\n",
              "      <td>1459514396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>CallJoinedEvent</td>\n",
              "      <td>148c9bab-da30-4518-94f9-ce16366b510d</td>\n",
              "      <td>Alexandra Chung</td>\n",
              "      <td>d467376c-70b5-4a16-8936-6cd73d50d70c</td>\n",
              "      <td>Gilbert Group</td>\n",
              "      <td>b328c9a0-d813-4f09-9a2c-3dc3a922c873</td>\n",
              "      <td>1459515260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CallJoinedEvent</td>\n",
              "      <td>10af11f1-6940-42d1-ad7f-a6d212b8c1f2</td>\n",
              "      <td>Phillip Marshall</td>\n",
              "      <td>d467376c-70b5-4a16-8936-6cd73d50d70c</td>\n",
              "      <td>Gilbert Group</td>\n",
              "      <td>b328c9a0-d813-4f09-9a2c-3dc3a922c873</td>\n",
              "      <td>1459515261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>CallJoinedEvent</td>\n",
              "      <td>148c9bab-da30-4518-94f9-ce16366b510d</td>\n",
              "      <td>Alexandra Chung</td>\n",
              "      <td>d467376c-70b5-4a16-8936-6cd73d50d70c</td>\n",
              "      <td>Gilbert Group</td>\n",
              "      <td>b328c9a0-d813-4f09-9a2c-3dc3a922c873</td>\n",
              "      <td>1459519087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>CallLeftEvent</td>\n",
              "      <td>148c9bab-da30-4518-94f9-ce16366b510d</td>\n",
              "      <td>Alexandra Chung</td>\n",
              "      <td>d467376c-70b5-4a16-8936-6cd73d50d70c</td>\n",
              "      <td>Gilbert Group</td>\n",
              "      <td>b328c9a0-d813-4f09-9a2c-3dc3a922c873</td>\n",
              "      <td>1459519086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>CallLeftEvent</td>\n",
              "      <td>2e21e535-8ecb-45b3-a92a-a3476e08b5d6</td>\n",
              "      <td>James Mckenzie</td>\n",
              "      <td>d467376c-70b5-4a16-8936-6cd73d50d70c</td>\n",
              "      <td>Gilbert Group</td>\n",
              "      <td>347404db-f71d-4be9-a046-222af3793ee6</td>\n",
              "      <td>1459523217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>CallLeftEvent</td>\n",
              "      <td>b3d1aee2-6a09-456d-b6fa-f4893af5ccc1</td>\n",
              "      <td>Jeanette Rich</td>\n",
              "      <td>d467376c-70b5-4a16-8936-6cd73d50d70c</td>\n",
              "      <td>Gilbert Group</td>\n",
              "      <td>347404db-f71d-4be9-a046-222af3793ee6</td>\n",
              "      <td>1459523216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>CallLeftEvent</td>\n",
              "      <td>2e21e535-8ecb-45b3-a92a-a3476e08b5d6</td>\n",
              "      <td>James Mckenzie</td>\n",
              "      <td>d467376c-70b5-4a16-8936-6cd73d50d70c</td>\n",
              "      <td>Gilbert Group</td>\n",
              "      <td>347404db-f71d-4be9-a046-222af3793ee6</td>\n",
              "      <td>1459523675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>CallCreatedEvent</td>\n",
              "      <td>2abd6c7e-bb4d-4ca2-a1d0-47eeee568720</td>\n",
              "      <td>Marcus Coleman</td>\n",
              "      <td>cac847f3-3ab7-4cf1-b2fc-43eff75ee6b0</td>\n",
              "      <td>Williams-Goodwin</td>\n",
              "      <td>3477f8ed-1f6f-4b4e-8868-db4a83ac1637</td>\n",
              "      <td>1459523676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>CallLeftEvent</td>\n",
              "      <td>2abd6c7e-bb4d-4ca2-a1d0-47eeee568720</td>\n",
              "      <td>Marcus Coleman</td>\n",
              "      <td>cac847f3-3ab7-4cf1-b2fc-43eff75ee6b0</td>\n",
              "      <td>Williams-Goodwin</td>\n",
              "      <td>3477f8ed-1f6f-4b4e-8868-db4a83ac1637</td>\n",
              "      <td>1459526281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>CallCreatedEvent</td>\n",
              "      <td>6f94458c-28f5-47d2-b66e-79e3c09fa9f6</td>\n",
              "      <td>Stephanie Esparza</td>\n",
              "      <td>d467376c-70b5-4a16-8936-6cd73d50d70c</td>\n",
              "      <td>Gilbert Group</td>\n",
              "      <td>3478855d-16a6-481a-a406-337b71503e83</td>\n",
              "      <td>1459526283</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          event_type  ...   timestamp\n",
              "0      CallLeftEvent  ...  1459488133\n",
              "1      CallLeftEvent  ...  1459488133\n",
              "2   CallCreatedEvent  ...  1459512944\n",
              "3      CallLeftEvent  ...  1459512942\n",
              "4   CallCreatedEvent  ...  1459513453\n",
              "5      CallLeftEvent  ...  1459513453\n",
              "6   CallCreatedEvent  ...  1459514077\n",
              "7      CallLeftEvent  ...  1459514074\n",
              "8   CallCreatedEvent  ...  1459514395\n",
              "9    CallJoinedEvent  ...  1459514396\n",
              "10   CallJoinedEvent  ...  1459515260\n",
              "11   CallJoinedEvent  ...  1459515261\n",
              "12   CallJoinedEvent  ...  1459519087\n",
              "13     CallLeftEvent  ...  1459519086\n",
              "14     CallLeftEvent  ...  1459523217\n",
              "15     CallLeftEvent  ...  1459523216\n",
              "16     CallLeftEvent  ...  1459523675\n",
              "17  CallCreatedEvent  ...  1459523676\n",
              "18     CallLeftEvent  ...  1459526281\n",
              "19  CallCreatedEvent  ...  1459526283\n",
              "\n",
              "[20 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeulNDYxX9KY"
      },
      "source": [
        "generated_data.to_csv(\"gdrive/My Drive/tonic/call_model_ordered_by_call_id.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx6oAj7dV11f"
      },
      "source": [
        "generated_data.to_csv(\"gdrive/My Drive/tonic/call_model_trained_.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}